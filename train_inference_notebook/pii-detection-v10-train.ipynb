{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V10: Fine-Tune DeBERTa-V3-Small \n",
    "- Train Data\n",
    "- Down Sampling 'O' Label 0.30\n",
    "- External Dataset \n",
    "- Evaluation Metric F-Beta5\n",
    "- Cross Validation\n",
    "- Max Length 2048\n",
    "- No Stride\n",
    "\n",
    "Trained on Kaggle with GPU T4 x2\n",
    "\n",
    "Inference\n",
    "- Max Length 4096\n",
    "- No Stride\n",
    "​\n",
    "Leaderboard \n",
    "- Public Score: 0.957\n",
    "- Private Score: 0.948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-22T12:10:56.138111Z",
     "iopub.status.busy": "2024-04-22T12:10:56.137849Z",
     "iopub.status.idle": "2024-04-22T12:11:25.493871Z",
     "shell.execute_reply": "2024-04-22T12:11:25.492899Z",
     "shell.execute_reply.started": "2024-04-22T12:10:56.138086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m712.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=700c2c669f189f0216815f2d5e3f1b3b28028fdab4c3922727d03fad65664b2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:25.496184Z",
     "iopub.status.busy": "2024-04-22T12:11:25.495886Z",
     "iopub.status.idle": "2024-04-22T12:11:45.272630Z",
     "shell.execute_reply": "2024-04-22T12:11:45.271665Z",
     "shell.execute_reply.started": "2024-04-22T12:11:25.496153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 12:11:35.646475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-22 12:11:35.646633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-22 12:11:35.802308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:45.274525Z",
     "iopub.status.busy": "2024-04-22T12:11:45.273844Z",
     "iopub.status.idle": "2024-04-22T12:11:45.283283Z",
     "shell.execute_reply": "2024-04-22T12:11:45.282306Z",
     "shell.execute_reply.started": "2024-04-22T12:11:45.274492Z"
    }
   },
   "outputs": [],
   "source": [
    "class Setting:\n",
    "    seed = 42\n",
    "    base_dir = \"/kaggle/input\"\n",
    "\n",
    "    # data\n",
    "    data_train = f\"{base_dir}/pii-train/train.json\"\n",
    "    data_nbroad = f\"{base_dir}/pii-mistral/mixtral-8x7b-v1.json\"\n",
    "    data_valentinwerner = f\"{base_dir}/pii-label-specific/all_labels.json\"\n",
    "    data_alejopaulier = f\"{base_dir}/pii-fix-punctuation/pii_dataset_fixed.json\"\n",
    "    data_pjmathematician = f\"{base_dir}/pii-fix-punctuation/moredata_dataset_fixed.json\"\n",
    "    data_minhsienweng = f\"{base_dir}/pii-ai-generated/pii_dataset_Gemma.json\"\n",
    "    data_mandrilator = f\"{base_dir}/pii-mistral/all_labels.json\"\n",
    "    \n",
    "    down_sample_ratio = 0.30\n",
    "    n_split = 5\n",
    "\n",
    "    # model\n",
    "    model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "    model_train = '/kaggle/working/model/train'\n",
    "    model_final = '/kaggle/working/model/final'\n",
    "    max_length = 2048\n",
    "\n",
    "    # hyperparameter\n",
    "    epochs = 2\n",
    "    learning_rate = 3e-5\n",
    "    warmup_ratio = 0.1\n",
    "    lr_scheduler_type='cosine'\n",
    "    weight_decay = 0.01\n",
    "    grad_steps = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    # PII (NER) tags\n",
    "    labels = [\"B-EMAIL\", \"B-ID_NUM\", \"B-NAME_STUDENT\", \"B-PHONE_NUM\",\n",
    "              \"B-STREET_ADDRESS\", \"B-URL_PERSONAL\", \"B-USERNAME\",\n",
    "              \"I-ID_NUM\", \"I-NAME_STUDENT\", \"I-PHONE_NUM\",\n",
    "              \"I-STREET_ADDRESS\",\"I-URL_PERSONAL\",\"O\"]\n",
    "    id2label = dict(enumerate(labels)) # integer label to BIO format label mapping\n",
    "    label2id = {v:k for k,v in id2label.items()} # BIO format label to integer label mapping\n",
    "    num_labels = len(labels) # number of PII (NER) tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:45.286221Z",
     "iopub.status.busy": "2024-04-22T12:11:45.285879Z",
     "iopub.status.idle": "2024-04-22T12:11:45.327874Z",
     "shell.execute_reply": "2024-04-22T12:11:45.326879Z",
     "shell.execute_reply.started": "2024-04-22T12:11:45.286193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79c0fd4a28f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(Setting.seed)\n",
    "torch.manual_seed(Setting.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:45.329393Z",
     "iopub.status.busy": "2024-04-22T12:11:45.329125Z",
     "iopub.status.idle": "2024-04-22T12:11:54.687029Z",
     "shell.execute_reply": "2024-04-22T12:11:54.685983Z",
     "shell.execute_reply.started": "2024-04-22T12:11:45.329370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27442 entries, 0 to 27441\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tokens      27442 non-null  object\n",
      " 1   pii_labels  27442 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 428.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# read and combine all dataset\n",
    "df_train = pd.read_json(Setting.data_train)\n",
    "df_nbroad = pd.read_json(Setting.data_nbroad)\n",
    "df_valentinwerner = pd.read_json(Setting.data_valentinwerner)\n",
    "df_alejopaulier = pd.read_json(Setting.data_alejopaulier)\n",
    "df_pjmathematician = pd.read_json(Setting.data_pjmathematician)\n",
    "df_minhsienweng = pd.read_json(Setting.data_minhsienweng)\n",
    "df_mandrilator = pd.read_json(Setting.data_mandrilator)\n",
    "\n",
    "features = ['tokens', 'labels']\n",
    "df = pd.concat([df_train[features],\n",
    "                   df_nbroad[features],\n",
    "                   df_valentinwerner[features],\n",
    "                   df_alejopaulier[features],\n",
    "                   df_pjmathematician[features],\n",
    "                   df_minhsienweng[features],\n",
    "                   df_mandrilator[features]],\n",
    "                   ignore_index=True)\n",
    "\n",
    "df = df[['tokens', 'labels']]\n",
    "df.rename(columns={\"labels\": \"pii_labels\"}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:54.689175Z",
     "iopub.status.busy": "2024-04-22T12:11:54.688486Z",
     "iopub.status.idle": "2024-04-22T12:11:54.701634Z",
     "shell.execute_reply": "2024-04-22T12:11:54.700582Z",
     "shell.execute_reply.started": "2024-04-22T12:11:54.689140Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bar_chart(data, target_column, title, xlabel, ylabel):\n",
    "    target = data[target_column].value_counts(sort=False).reset_index(name='total')\n",
    "    ax = sns.barplot(\n",
    "        data=target,\n",
    "        y='total',\n",
    "        x=target_column,\n",
    "        hue=target_column,\n",
    "        palette='cool',\n",
    "        estimator=lambda x: sum(x)*100.00/target['total'].sum())\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(xlabel, fontdict={'weight': 'bold'})\n",
    "    plt.ylabel(ylabel, fontdict={'weight': 'bold'})\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=9)\n",
    "    # show percentage on bar for first 3 bars\n",
    "    for index, row in target.iterrows():\n",
    "        y = row.total*100.00/target['total'].sum()\n",
    "        ax.text(row.name, y + 0.15, f'{y:.2f}%', fontsize=9)\n",
    "    ax.get_legend().remove()\n",
    "    plt.show()\n",
    "\n",
    "def down_sample(df, down_sample_ratio, seed):\n",
    "    df['non_pii_entity_only'] = df['pii_labels'].apply(lambda x: sum(label=='O' for label in x)==len(x))\n",
    "\n",
    "    df_non_pii_entity_only = df[df['non_pii_entity_only']].sample(frac=down_sample_ratio, random_state=seed)\n",
    "    df_with_pii_entity = df[~df['non_pii_entity_only']]\n",
    "    df = pd.concat([df_with_pii_entity, df_non_pii_entity_only])\n",
    "\n",
    "    plot_bar_chart(df, 'non_pii_entity_only', \"% of Documents with Non-PII Entity ('O' Label) Only\", \"Non-PII Entity\", \"Percentage\")\n",
    "    print(df['non_pii_entity_only'].value_counts())\n",
    "\n",
    "    df.drop(columns=['non_pii_entity_only'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:54.703461Z",
     "iopub.status.busy": "2024-04-22T12:11:54.703109Z",
     "iopub.status.idle": "2024-04-22T12:11:56.023699Z",
     "shell.execute_reply": "2024-04-22T12:11:56.022758Z",
     "shell.execute_reply.started": "2024-04-22T12:11:54.703429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_pii_entity_only\n",
      "False    20430\n",
      "True      2104\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22534 entries, 0 to 23091\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tokens      22534 non-null  object\n",
      " 1   pii_labels  22534 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 528.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = down_sample(df, Setting.down_sample_ratio, Setting.seed)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:56.025314Z",
     "iopub.status.busy": "2024-04-22T12:11:56.024969Z",
     "iopub.status.idle": "2024-04-22T12:11:58.519979Z",
     "shell.execute_reply": "2024-04-22T12:11:58.519019Z",
     "shell.execute_reply.started": "2024-04-22T12:11:56.025286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'pii_labels', '__index_level_0__'],\n",
       "    num_rows: 22534\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:58.521496Z",
     "iopub.status.busy": "2024-04-22T12:11:58.521176Z",
     "iopub.status.idle": "2024-04-22T12:11:58.528743Z",
     "shell.execute_reply": "2024-04-22T12:11:58.527867Z",
     "shell.execute_reply.started": "2024-04-22T12:11:58.521471Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, tokenizer, label2id, max_length):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, max_length=max_length, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"pii_labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.       \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:58.531419Z",
     "iopub.status.busy": "2024-04-22T12:11:58.531172Z",
     "iopub.status.idle": "2024-04-22T12:11:58.544794Z",
     "shell.execute_reply": "2024-04-22T12:11:58.544069Z",
     "shell.execute_reply.started": "2024-04-22T12:11:58.531394Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    report = classification_report(y_true=true_labels, y_pred=true_predictions, output_dict=True)\n",
    "    micro_avg = report.pop(\"micro avg\")    \n",
    "    \n",
    "    precision = micro_avg[\"precision\"]\n",
    "    recall = micro_avg[\"recall\"]\n",
    "    beta = 5\n",
    "    fbeta = ((1+(beta**2))*precision*recall) / ((beta**2)*precision + recall)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": micro_avg[\"f1-score\"],\n",
    "        \"fb-5\": fbeta\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:11:58.546417Z",
     "iopub.status.busy": "2024-04-22T12:11:58.546079Z",
     "iopub.status.idle": "2024-04-22T12:14:28.107517Z",
     "shell.execute_reply": "2024-04-22T12:14:28.106668Z",
     "shell.execute_reply.started": "2024-04-22T12:11:58.546388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:29<00:00, 29.91s/it]\n"
     ]
    }
   ],
   "source": [
    "folds = [\n",
    "    (\n",
    "        np.array([i for i, d in enumerate(ds[\"pii_labels\"]) if i % Setting.n_split != s]),\n",
    "        np.array([i for i, d in enumerate(ds[\"pii_labels\"]) if i % Setting.n_split == s])\n",
    "    )\n",
    "    for s in tqdm(range(Setting.n_split))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:14:48.820517Z",
     "iopub.status.busy": "2024-04-22T12:14:48.820189Z",
     "iopub.status.idle": "2024-04-22T12:14:59.489960Z",
     "shell.execute_reply": "2024-04-22T12:14:59.488972Z",
     "shell.execute_reply.started": "2024-04-22T12:14:48.820492Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T07:11:21.276223Z",
     "iopub.status.busy": "2024-04-22T07:11:21.275589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, train_ds: 18027, val_ds:  4507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1497c0a6205e458294b648e290efc2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab94f7191e4d4db08edf1f3daa966f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, tokenized_train_ds: 18027, tokenized_val_ds:  4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4506' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4506/4506 1:12:16, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Fb-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.955940</td>\n",
       "      <td>0.892964</td>\n",
       "      <td>0.923380</td>\n",
       "      <td>0.895233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.936750</td>\n",
       "      <td>0.927790</td>\n",
       "      <td>0.932248</td>\n",
       "      <td>0.928131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-4506\n",
      "------------------------------------------------------\n",
      "Fold: 1, train_ds: 18027, val_ds:  4507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdb2e60c9d04950a7f8803babc8831a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d1c99c05c4db39ebbe1bde129dadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, tokenized_train_ds: 18027, tokenized_val_ds:  4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1016' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1016/4506 14:28 < 49:48, 1.17 it/s, Epoch 0.45/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Setting.model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=Setting.model_train,\n",
    "    num_train_epochs=Setting.epochs,\n",
    "    learning_rate=Setting.learning_rate,\n",
    "    lr_scheduler_type=Setting.lr_scheduler_type,\n",
    "    warmup_ratio=Setting.warmup_ratio,\n",
    "    weight_decay=Setting.weight_decay,\n",
    "    gradient_accumulation_steps=Setting.grad_steps,\n",
    "    per_device_train_batch_size=Setting.batch_size,\n",
    "    per_device_eval_batch_size=Setting.batch_size,\n",
    "    seed=Setting.seed,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"fb-5\",\n",
    "    logging_steps=10,\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):        \n",
    "    train_ds = ds.select(train_idx)\n",
    "    val_ds = ds.select(val_idx)\n",
    "    print(f'Fold: {fold_idx}, train_ds: {train_ds.num_rows}, val_ds:  {val_ds.num_rows}')    \n",
    "    tokenized_train_ds = train_ds.map(tokenize_and_align_labels, \n",
    "                                         fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                     \"label2id\": Setting.label2id, \n",
    "                                                     \"max_length\": Setting.max_length\n",
    "                                                    }, \n",
    "                                         batched=True)\n",
    "    tokenized_train_ds = tokenized_train_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    tokenized_val_ds = val_ds.map(tokenize_and_align_labels, \n",
    "                                     fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                 \"label2id\": Setting.label2id, \n",
    "                                                 \"max_length\": Setting.max_length\n",
    "                                                }, \n",
    "                                     batched=True)\n",
    "    tokenized_val_ds = tokenized_val_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    print(f'Fold: {fold_idx}, tokenized_train_ds: {tokenized_train_ds.num_rows}, tokenized_val_ds:  {tokenized_val_ds.num_rows}') \n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        Setting.model_checkpoint, \n",
    "        num_labels=Setting.num_labels, \n",
    "        id2label=Setting.id2label, \n",
    "        label2id=Setting.label2id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_ds,\n",
    "        eval_dataset=tokenized_val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=partial(compute_metrics, id2label=Setting.id2label)\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    # set best model checkpoint\n",
    "    Setting.model_checkpoint = trainer.state.best_model_checkpoint\n",
    "    print(Setting.model_checkpoint)\n",
    "    trainer.save_model(Setting.model_final)\n",
    "    tokenizer.save_pretrained(Setting.model_final)\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:15:12.401132Z",
     "iopub.status.busy": "2024-04-22T12:15:12.400482Z",
     "iopub.status.idle": "2024-04-22T12:15:12.405207Z",
     "shell.execute_reply": "2024-04-22T12:15:12.404206Z",
     "shell.execute_reply.started": "2024-04-22T12:15:12.401098Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T12:17:15.095639Z",
     "iopub.status.busy": "2024-04-22T12:17:15.095009Z",
     "iopub.status.idle": "2024-04-22T13:33:08.669252Z",
     "shell.execute_reply": "2024-04-22T13:33:08.667869Z",
     "shell.execute_reply.started": "2024-04-22T12:17:15.095608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pii-data-with-deberta-v3-small/model/train/checkpoint-4506\n",
      "Fold: 1, train_ds: 18027, val_ds:  4507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb06f9639aaa4e7a840f65ea18e280bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc094ad2fa849d1984c662d0c3c7884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, tokenized_train_ds: 18027, tokenized_val_ds:  4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240422_121911-qh029fur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bst_6041/huggingface/runs/qh029fur' target=\"_blank\">eager-dream-8</a></strong> to <a href='https://wandb.ai/bst_6041/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bst_6041/huggingface' target=\"_blank\">https://wandb.ai/bst_6041/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bst_6041/huggingface/runs/qh029fur' target=\"_blank\">https://wandb.ai/bst_6041/huggingface/runs/qh029fur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4506' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4506/4506 1:12:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Fb-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.924102</td>\n",
       "      <td>0.902748</td>\n",
       "      <td>0.913300</td>\n",
       "      <td>0.903551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.953396</td>\n",
       "      <td>0.927130</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.928113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-4506\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     80\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_final\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, Setting\u001b[38;5;241m.\u001b[39mmodel_final)\n\u001b[0;32m---> 81\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Training crashed at fold #1, retrain from checkpoing /kaggle/working/model/train/checkpoint-4506\n",
    "Setting.model_checkpoint = '/kaggle/input/pii-data-with-deberta-v3-small/model/train/checkpoint-4506'\n",
    "print(Setting.model_checkpoint)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Setting.model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=Setting.model_train,\n",
    "    num_train_epochs=Setting.epochs,\n",
    "    learning_rate=Setting.learning_rate,\n",
    "    lr_scheduler_type=Setting.lr_scheduler_type,\n",
    "    warmup_ratio=Setting.warmup_ratio,\n",
    "    weight_decay=Setting.weight_decay,\n",
    "    gradient_accumulation_steps=Setting.grad_steps,\n",
    "    per_device_train_batch_size=Setting.batch_size,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=Setting.seed,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"fb-5\",\n",
    "    logging_steps=100,\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    if fold_idx < 1:\n",
    "        # skip fold 0\n",
    "        continue\n",
    "    train_ds = ds.select(train_idx)\n",
    "    val_ds = ds.select(val_idx)\n",
    "    print(f'Fold: {fold_idx}, train_ds: {train_ds.num_rows}, val_ds:  {val_ds.num_rows}')    \n",
    "    tokenized_train_ds = train_ds.map(tokenize_and_align_labels, \n",
    "                                         fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                     \"label2id\": Setting.label2id, \n",
    "                                                     \"max_length\": Setting.max_length\n",
    "                                                    }, \n",
    "                                         batched=True)\n",
    "    tokenized_train_ds = tokenized_train_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    tokenized_val_ds = val_ds.map(tokenize_and_align_labels, \n",
    "                                     fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                 \"label2id\": Setting.label2id, \n",
    "                                                 \"max_length\": Setting.max_length\n",
    "                                                }, \n",
    "                                     batched=True)\n",
    "    tokenized_val_ds = tokenized_val_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    print(f'Fold: {fold_idx}, tokenized_train_ds: {tokenized_train_ds.num_rows}, tokenized_val_ds:  {tokenized_val_ds.num_rows}') \n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        Setting.model_checkpoint, \n",
    "        num_labels=Setting.num_labels, \n",
    "        id2label=Setting.id2label, \n",
    "        label2id=Setting.label2id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_ds,\n",
    "        eval_dataset=tokenized_val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=partial(compute_metrics, id2label=Setting.id2label)\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    # set best model checkpoint\n",
    "    Setting.model_checkpoint = trainer.state.best_model_checkpoint\n",
    "    print(Setting.model_checkpoint)\n",
    "    trainer.save_model(Setting.model_final)\n",
    "    tokenizer.save_pretrained(Setting.model_final)\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(5)\n",
    "    shutil.make_archive('model_final', 'zip', Setting.model_final)\n",
    "    shutil.make_archive('best_model_checkpoint', 'zip', ng.model_checkpoint)\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T13:43:46.711548Z",
     "iopub.status.busy": "2024-04-22T13:43:46.710798Z",
     "iopub.status.idle": "2024-04-22T13:45:52.121571Z",
     "shell.execute_reply": "2024-04-22T13:45:52.120368Z",
     "shell.execute_reply.started": "2024-04-22T13:43:46.711517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/checkpoint-4506.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive('model_final_1', 'zip', Setting.model_final)\n",
    "shutil.make_archive('checkpoint-4506', 'zip', Setting.model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T13:45:52.124005Z",
     "iopub.status.busy": "2024-04-22T13:45:52.123625Z",
     "iopub.status.idle": "2024-04-22T13:45:52.134131Z",
     "shell.execute_reply": "2024-04-22T13:45:52.132968Z",
     "shell.execute_reply.started": "2024-04-22T13:45:52.123969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-4506\n"
     ]
    }
   ],
   "source": [
    "print(Setting.model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T13:46:07.211458Z",
     "iopub.status.busy": "2024-04-22T13:46:07.211101Z",
     "iopub.status.idle": "2024-04-22T15:01:12.108646Z",
     "shell.execute_reply": "2024-04-22T15:01:12.107206Z",
     "shell.execute_reply.started": "2024-04-22T13:46:07.211424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2, train_ds: 18027, val_ds:  4507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0d12529033422cbb66bf3a7d1269e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa456ec65751449f948dc857b4bb3ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2, tokenized_train_ds: 18027, tokenized_val_ds:  4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4506' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4506/4506 1:12:46, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Fb-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.969645</td>\n",
       "      <td>0.915381</td>\n",
       "      <td>0.941732</td>\n",
       "      <td>0.917356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.960509</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.949291</td>\n",
       "      <td>0.939167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-4506\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     76\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_final_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, Setting\u001b[38;5;241m.\u001b[39mmodel_final)\n\u001b[0;32m---> 77\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_checkpoint_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mng\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_checkpoint)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ng' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Setting.model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=Setting.model_train,\n",
    "    num_train_epochs=Setting.epochs,\n",
    "    learning_rate=Setting.learning_rate,\n",
    "    lr_scheduler_type=Setting.lr_scheduler_type,\n",
    "    warmup_ratio=Setting.warmup_ratio,\n",
    "    weight_decay=Setting.weight_decay,\n",
    "    gradient_accumulation_steps=Setting.grad_steps,\n",
    "    per_device_train_batch_size=Setting.batch_size,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=Setting.seed,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"fb-5\",\n",
    "    logging_steps=100,\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    if fold_idx < 2:\n",
    "        # skip fold 0 and 1\n",
    "        continue\n",
    "    train_ds = ds.select(train_idx)\n",
    "    val_ds = ds.select(val_idx)\n",
    "    print(f'Fold: {fold_idx}, train_ds: {train_ds.num_rows}, val_ds:  {val_ds.num_rows}')    \n",
    "    tokenized_train_ds = train_ds.map(tokenize_and_align_labels, \n",
    "                                         fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                     \"label2id\": Setting.label2id, \n",
    "                                                     \"max_length\": Setting.max_length\n",
    "                                                    }, \n",
    "                                         batched=True)\n",
    "    tokenized_train_ds = tokenized_train_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    tokenized_val_ds = val_ds.map(tokenize_and_align_labels, \n",
    "                                     fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                 \"label2id\": Setting.label2id, \n",
    "                                                 \"max_length\": Setting.max_length\n",
    "                                                }, \n",
    "                                     batched=True)\n",
    "    tokenized_val_ds = tokenized_val_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    print(f'Fold: {fold_idx}, tokenized_train_ds: {tokenized_train_ds.num_rows}, tokenized_val_ds:  {tokenized_val_ds.num_rows}') \n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        Setting.model_checkpoint, \n",
    "        num_labels=Setting.num_labels, \n",
    "        id2label=Setting.id2label, \n",
    "        label2id=Setting.label2id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_ds,\n",
    "        eval_dataset=tokenized_val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=partial(compute_metrics, id2label=Setting.id2label)\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    # set best model checkpoint\n",
    "    Setting.model_checkpoint = trainer.state.best_model_checkpoint\n",
    "    print(Setting.model_checkpoint)\n",
    "    trainer.save_model(Setting.model_final)\n",
    "    tokenizer.save_pretrained(Setting.model_final)\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(5)\n",
    "    shutil.make_archive(f'model_final_{fold_idx}', 'zip', Setting.model_final)\n",
    "    shutil.make_archive(f'best_model_checkpoint_{fold_idx}', 'zip', Setting.model_checkpoint)\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:06:15.914848Z",
     "iopub.status.busy": "2024-04-22T15:06:15.913972Z",
     "iopub.status.idle": "2024-04-22T17:38:55.931381Z",
     "shell.execute_reply": "2024-04-22T17:38:55.930366Z",
     "shell.execute_reply.started": "2024-04-22T15:06:15.914805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3, train_ds: 18027, val_ds:  4507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587821b62aeb42a284901071b8e075b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b33c805a0a645ac8051e66ae33701e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3, tokenized_train_ds: 18027, tokenized_val_ds:  4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4506' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4506/4506 1:12:42, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Fb-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.969520</td>\n",
       "      <td>0.932434</td>\n",
       "      <td>0.950615</td>\n",
       "      <td>0.933808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.968108</td>\n",
       "      <td>0.943906</td>\n",
       "      <td>0.955854</td>\n",
       "      <td>0.944814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-4506\n",
      "------------------------------------------------------\n",
      "Fold: 4, train_ds: 18028, val_ds:  4506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd48086c77941068ea2352fac0b0a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864fcc7316754b0daa598da58886de38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4506 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4, tokenized_train_ds: 18028, tokenized_val_ds:  4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4506' max='4506' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4506/4506 1:12:47, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Fb-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.936411</td>\n",
       "      <td>0.970269</td>\n",
       "      <td>0.953039</td>\n",
       "      <td>0.968921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.956807</td>\n",
       "      <td>0.965741</td>\n",
       "      <td>0.957488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/model/train/checkpoint-2253\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Setting.model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=Setting.model_train,\n",
    "    num_train_epochs=Setting.epochs,\n",
    "    learning_rate=Setting.learning_rate,\n",
    "    lr_scheduler_type=Setting.lr_scheduler_type,\n",
    "    warmup_ratio=Setting.warmup_ratio,\n",
    "    weight_decay=Setting.weight_decay,\n",
    "    gradient_accumulation_steps=Setting.grad_steps,\n",
    "    per_device_train_batch_size=Setting.batch_size,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=Setting.seed,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"fb-5\",\n",
    "    logging_steps=100,\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    if fold_idx < 3:\n",
    "        # skip fold 0 to 2\n",
    "        continue\n",
    "    train_ds = ds.select(train_idx)\n",
    "    val_ds = ds.select(val_idx)\n",
    "    print(f'Fold: {fold_idx}, train_ds: {train_ds.num_rows}, val_ds:  {val_ds.num_rows}')    \n",
    "    tokenized_train_ds = train_ds.map(tokenize_and_align_labels, \n",
    "                                         fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                     \"label2id\": Setting.label2id, \n",
    "                                                     \"max_length\": Setting.max_length\n",
    "                                                    }, \n",
    "                                         batched=True)\n",
    "    tokenized_train_ds = tokenized_train_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    tokenized_val_ds = val_ds.map(tokenize_and_align_labels, \n",
    "                                     fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                                 \"label2id\": Setting.label2id, \n",
    "                                                 \"max_length\": Setting.max_length\n",
    "                                                }, \n",
    "                                     batched=True)\n",
    "    tokenized_val_ds = tokenized_val_ds.remove_columns(['tokens', 'pii_labels'])\n",
    "    \n",
    "    print(f'Fold: {fold_idx}, tokenized_train_ds: {tokenized_train_ds.num_rows}, tokenized_val_ds:  {tokenized_val_ds.num_rows}') \n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        Setting.model_checkpoint, \n",
    "        num_labels=Setting.num_labels, \n",
    "        id2label=Setting.id2label, \n",
    "        label2id=Setting.label2id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_ds,\n",
    "        eval_dataset=tokenized_val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=partial(compute_metrics, id2label=Setting.id2label)\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    # set best model checkpoint\n",
    "    Setting.model_checkpoint = trainer.state.best_model_checkpoint\n",
    "    print(Setting.model_checkpoint)\n",
    "    trainer.save_model(Setting.model_final)\n",
    "    tokenizer.save_pretrained(Setting.model_final)\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(5)\n",
    "    shutil.make_archive(f'model_final_{fold_idx}', 'zip', Setting.model_final)\n",
    "    shutil.make_archive(f'best_model_checkpoint_{fold_idx}', 'zip', Setting.model_checkpoint)\n",
    "    print('------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4843115,
     "sourceId": 8180467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4843126,
     "sourceId": 8180483,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4843137,
     "sourceId": 8180504,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4843155,
     "sourceId": 8180531,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4843171,
     "sourceId": 8180557,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 173312449,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
